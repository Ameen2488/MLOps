# End-to-End MLOps Image Classification Project

## Project Overview
This project implements a complete MLOps pipeline for **Chest Cancer Image Classification** using a Convolutional Neural Network (CNN).

**Note:** This project follows the architecture and MLOps practices from a reference tutorial (originally for Kidney Disease), but has been adapted for Chest Cancer data.
**Future Goal:** While the initial implementation uses TensorFlow (following the tutorial), the project roadmap includes a migration to **PyTorch** for the modeling backend.

## Project Structure
The project follows a modular structure generated by `template.py`:

```
portfolio_projects/
├── src/
│   └── cnn_image_classifier/
│       ├── components/         # Modular components (Data Ingestion, Training, etc.)
│       ├── utils/              # Utility functions
│       ├── config/             # Configuration managers
│       ├── pipeline/           # Training and Prediction pipelines
│       ├── entity/             # Data classes for configuration
│       └── constants/          # Constant values
├── config/                     # Configuration files (config.yaml)
├── research/                   # Jupyter notebooks for experimentation
├── templates/                  # HTML templates for the web app
├── main.py                     # Entry point for the application
├── dvc.yaml                    # DVC pipeline configuration
└── params.yaml                 # Training parameters
```

## Setup Instructions

### 1. Environment Setup
It is recommended to use a virtual environment.

```bash
conda create -n chest-cancer python=3.8 -y
conda activate chest-cancer
```
*Or using venv:*
```bash
python -m venv .venv
.venv\Scripts\activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

> **Note:** This project uses specific versions of `tensorflow` (current), `dvc`, `mlflow`, and custom utilities via `python-box` and `ensure`.
> *PyTorch dependencies (`torch`) are also included for the future migration.*

### 3. Special Note on `ensure` Library
If you see `AttributeError: 'TestCase' object has no attribute 'assertRaisesRegexp'`, open `.venv/Lib/site-packages/ensure/main.py` and replace `assertRaisesRegexp` with `assertRaisesRegex`.

## Standard Development Workflow
For each stage of the pipeline (Data Ingestion, Training, Evaluation, etc.), follow these steps:

1.  **Update `config/config.yaml`**: Define file paths and configuration constants (e.g., Chest Cancer dataset URL).
2.  **Update `params.yaml`**: Update model parameters (epochs, batch size, etc.).
3.  **Update `src/entity/__init__.py`**: Update the Entity (Data Class) for the new config.
4.  **Update `src/config/configuration.py`**: Update the ConfigurationManager to read and return the new entity.
5.  **Update `src/components/`**: Create or update the component class.
6.  **Update `src/pipeline/`**: Create or update the pipeline to run the component.
7.  **Update `main.py`**: Integration and entry point.
8.  **Update `dvc.yaml`**: Add the stage to the DVC pipeline.

## Workflows and Tools

1.  **Experiment Tracking (MLflow)**: Tracks parameters, metrics, and models.
    *   Set `MLFLOW_TRACKING_URI`, `MLFLOW_TRACKING_USERNAME`, and `MLFLOW_TRACKING_PASSWORD`.
2.  **Data Version Control (DVC)**: Manages data and pipeline reproducibility.
    *   `dvc init`
    *   `dvc repro`
3.  **CI/CD (GitHub Actions)**: Automates deployment.
    *   **Build**: Docker image creation.
    *   **Push**: Push image to AWS ECR (Elastic Container Registry).
    *   **Deploy**: Pull and run image on AWS EC2 (Elastic Compute Cloud) as a Self-Hosted Runner.

## AWS CI/CD Deployment Steps

1.  **Login to AWS Console**.
2.  **Create IAM User**: With `EC2InstanceConnect` and `EC2ContainerRegistryFullAccess`.
3.  **Create ECR Repository**: To store the Docker image.
    *   Save the URI: `566373416292.dkr.ecr.us-east-1.amazonaws.com/chest-cancer`
4.  **Create EC2 Instance**: Ubuntu machine to run the application.
5.  **Configure EC2 as Self-Hosted Runner**:
    *   Go to GitHub Repo -> Settings -> Actions -> Runners -> New self-hosted runner.
    *   Run the provided commands on the EC2 instance.
6.  **Setup GitHub Secrets**:
    *   `AWS_ACCESS_KEY_ID`
    *   `AWS_SECRET_ACCESS_KEY`
    *   `AWS_REGION` (e.g., us-east-1)
    *   `AWS_ECR_LOGIN_URI`
    *   `ECR_REPOSITORY_NAME`
