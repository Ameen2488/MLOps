{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 4: Data Leakage Detection & Prevention\n",
                "\n",
                "**Module 3: Data & Pipeline Engineering** | **Time**: 4-5 hours | **Difficulty**: Intermediate-Advanced\n",
                "\n",
                "---\n",
                "\n",
                "## \ud83c\udfaf Learning Objectives\n",
                "\n",
                "\u2705 Understand what data leakage is and why it\u2019s the most insidious ML bug  \n",
                "\u2705 Identify the 3 main types of leakage (target, train-test, temporal)  \n",
                "\u2705 Build leak-free preprocessing pipelines  \n",
                "\u2705 Detect leakage in existing pipelines  \n",
                "\u2705 Answer 5 interview questions on data leakage  \n",
                "\n",
                "---\n",
                "\n",
                "## \ud83d\udcda Table of Contents\n",
                "\n",
                "1. [What Is Data Leakage?](#1-what-is-leakage)\n",
                "2. [Type 1: Target Leakage](#2-target-leakage)\n",
                "3. [Type 2: Train-Test Contamination](#3-train-test)\n",
                "4. [Type 3: Temporal Leakage](#4-temporal)\n",
                "5. [Building Leak-Free Pipelines](#5-leak-free)\n",
                "6. [Hands-On: Leaky vs Clean Pipeline](#6-hands-on)\n",
                "7. [Leakage Detection Checklist](#7-checklist)\n",
                "8. [Exercises](#8-exercises)\n",
                "9. [Interview Preparation](#9-interview)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. What Is Data Leakage? <a id='1-what-is-leakage'></a>\n",
                "\n",
                "Data leakage occurs when **information from outside the training dataset** is used to create the model, leading to **overly optimistic performance** during development that **doesn\u2019t hold in production**.\n",
                "\n",
                "### The Danger\n",
                "\n",
                "```\n",
                "                 WITH LEAKAGE                    WITHOUT LEAKAGE\n",
                "              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "  Dev:        \u2502  Accuracy: 99%  \u2502          \u2502  Accuracy: 85%  \u2502\n",
                "              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "  Production: \u2502  Accuracy: 55%  \u2502  \ud83d\udca5      \u2502  Accuracy: 83%  \u2502  \u2705\n",
                "              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "```\n",
                "\n",
                "### Leakage Flow Diagram\n",
                "\n",
                "```\n",
                "  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "  \u2502                 THREE TYPES OF LEAKAGE                  \u2502\n",
                "  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
                "  \u2502 TARGET LEAKAGE  \u2502 TRAIN-TEST LEAK \u2502 TEMPORAL LEAKAGE    \u2502\n",
                "  \u2502                \u2502                \u2502                     \u2502\n",
                "  \u2502 Features that  \u2502 Info from test \u2502 Future info used    \u2502\n",
                "  \u2502 encode the     \u2502 set leaks into \u2502 to predict past     \u2502\n",
                "  \u2502 target label   \u2502 training       \u2502 events              \u2502\n",
                "  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "```\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Type 1: Target Leakage <a id='2-target-leakage'></a>\n",
                "\n",
                "When a **feature directly encodes the target variable** \u2014 information that would NOT be available at prediction time.\n",
                "\n",
                "### Classic Examples\n",
                "\n",
                "| Task | Leaky Feature | Why It Leaks |\n",
                "|------|--------------|---------------|\n",
                "| Predict hospital readmission | `discharge_notes` | Only exist AFTER discharge decision |\n",
                "| Predict loan default | `collection_agency_id` | Only assigned AFTER default |\n",
                "| Predict churn | `cancellation_reason` | Only known AFTER churning |\n",
                "| Predict click | `purchase_amount` | Purchase happens AFTER click |\n",
                "\n",
                "### Visual: Timeline of Feature Availability\n",
                "\n",
                "```\n",
                "  PREDICTION POINT\n",
                "        \u2502\n",
                "  TIME  \u25bc\n",
                "  \u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\n",
                "       \u2502\n",
                "  \u2705 Features available      \u274c Features NOT available\n",
                "  at prediction time:       at prediction time:\n",
                "  - user_age               - discharge_notes\n",
                "  - prior_visits           - cancellation_reason\n",
                "  - account_age            - collection_agency_id\n",
                "```\n",
                "\n",
                "### The Heuristic\n",
                "\n",
                "> **Ask yourself: \"Would I have this feature at the time I need to make a prediction?\"**  \n",
                "> If the answer is **NO**, it\u2019s leakage. Remove it.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Type 2: Train-Test Contamination <a id='3-train-test'></a>\n",
                "\n",
                "When information from the **test set leaks into the training process**.\n",
                "\n",
                "### Most Common Cause: Preprocessing Before Splitting\n",
                "\n",
                "```\n",
                "  \u274c WRONG (Leaky Pipeline):\n",
                "  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "  \u2502  ALL DATA   \u2502\u2500\u25b6\u2502 Normalize on  \u2502\u2500\u25b6\u2502  Split    \u2502\n",
                "  \u2502             \u2502    \u2502 ENTIRE dataset\u2502    \u2502 train/test\u2502\n",
                "  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "       Test set statistics are embedded in training data! \ud83d\udca5\n",
                "\n",
                "  \u2705 CORRECT (Clean Pipeline):\n",
                "  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "  \u2502  ALL DATA   \u2502\u2500\u25b6\u2502  Split    \u2502\u2500\u25b6\u2502 Normalize on  \u2502\n",
                "  \u2502             \u2502    \u2502 train/test\u2502    \u2502 TRAIN only    \u2502\n",
                "  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "       fit on train, transform both train AND test\n",
                "```\n",
                "\n",
                "### Common Train-Test Leaks\n",
                "\n",
                "| Action | Leaky | Clean |\n",
                "|--------|-------|-------|\n",
                "| StandardScaler | `scaler.fit(ALL_DATA)` | `scaler.fit(X_train)` |\n",
                "| Missing value imputation | Impute on all data | Impute stats from train only |\n",
                "| Feature selection | Select features on all data | Select features on train only |\n",
                "| Oversampling (SMOTE) | SMOTE before split | SMOTE on train only |\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Type 3: Temporal Leakage <a id='4-temporal'></a>\n",
                "\n",
                "Using **future information to predict past events**. Especially dangerous with time-series data.\n",
                "\n",
                "### Visual: Temporal Split vs Random Split\n",
                "\n",
                "```\n",
                "  \u274c RANDOM SPLIT (leaky for time-series):\n",
                "  Time: Jan   Feb   Mar   Apr   May   Jun   Jul   Aug\n",
                "        [T]   [V]   [T]   [T]   [V]   [T]   [V]   [T]\n",
                "        T=Train, V=Validation\n",
                "        February data \"knows\" about March-August! \ud83d\udca5\n",
                "\n",
                "  \u2705 TEMPORAL SPLIT (correct):\n",
                "  Time: Jan   Feb   Mar   Apr   May   Jun  | Jul   Aug\n",
                "        [  T   R   A   I   N   I   N   G  ]|[ T E S T ]\n",
                "        Past data only \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6| Future\n",
                "```\n",
                "\n",
                "### Examples of Temporal Leakage\n",
                "\n",
                "| Scenario | Leak | Fix |\n",
                "|----------|------|-----|\n",
                "| Stock prediction | Using tomorrow\u2019s moving average | Use only past-looking windows |\n",
                "| Churn prediction | Including next month\u2019s activity | Use only historical features |\n",
                "| Demand forecasting | Including actual sales as feature | Use only data up to prediction point |\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Building Leak-Free Pipelines <a id='5-leak-free'></a>\n",
                "\n",
                "### The Solution: `sklearn.pipeline.Pipeline`\n",
                "\n",
                "Scikit-learn\u2019s Pipeline ensures that **fitting happens only on training data**:\n",
                "\n",
                "```\n",
                "  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "  \u2502 Imputer   \u2502\u2500\u25b6\u2502 Scaler      \u2502\u2500\u25b6\u2502 Encoder     \u2502\u2500\u25b6\u2502 Model      \u2502\n",
                "  \u2502 (fit on   \u2502    \u2502 (fit on     \u2502    \u2502 (fit on     \u2502    \u2502 (fit on    \u2502\n",
                "  \u2502  train)   \u2502    \u2502  train)     \u2502    \u2502  train)     \u2502    \u2502  train)    \u2502\n",
                "  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "  pipeline.fit(X_train, y_train)  \u2192  All steps fit on train ONLY\n",
                "  pipeline.predict(X_test)        \u2192  All steps transform (no refit)\n",
                "```\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# DEMO: Leaky vs Clean Pipeline\n",
                "# ============================================================\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import accuracy_score, f1_score\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "# Generate synthetic classification data\n",
                "n = 5000\n",
                "X = np.random.randn(n, 10)\n",
                "# Introduce missing values (~10%)\n",
                "mask = np.random.random(X.shape) < 0.1\n",
                "X[mask] = np.nan\n",
                "y = (X[:, 0] + X[:, 1] * 0.5 + np.random.randn(n) * 0.3 > 0).astype(int)\n",
                "# Fix NaN effects on y\n",
                "X_df = pd.DataFrame(X, columns=[f'feat_{i}' for i in range(10)])\n",
                "y = pd.Series(y)\n",
                "\n",
                "print(f\"Dataset: {X_df.shape}, Missing values: {X_df.isna().sum().sum()}\")\n",
                "print(f\"Class distribution: {dict(y.value_counts())}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# \u274c LEAKY PIPELINE: Preprocess BEFORE splitting\n",
                "# ============================================================\n",
                "print(\"=\"*60)\n",
                "print(\"\u274c LEAKY PIPELINE\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Impute on ALL data (leak!)\n",
                "imputer_leak = SimpleImputer(strategy='mean')\n",
                "X_imputed = imputer_leak.fit_transform(X_df)\n",
                "\n",
                "# Scale on ALL data (leak!)\n",
                "scaler_leak = StandardScaler()\n",
                "X_scaled = scaler_leak.fit_transform(X_imputed)\n",
                "\n",
                "# NOW split (too late! Statistics from test set already embedded)\n",
                "X_train_leak, X_test_leak, y_train_leak, y_test_leak = train_test_split(\n",
                "    X_scaled, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# Train and evaluate\n",
                "rf_leak = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_leak.fit(X_train_leak, y_train_leak)\n",
                "y_pred_leak = rf_leak.predict(X_test_leak)\n",
                "\n",
                "acc_leak = accuracy_score(y_test_leak, y_pred_leak)\n",
                "f1_leak = f1_score(y_test_leak, y_pred_leak)\n",
                "print(f\"  Accuracy: {acc_leak:.4f}\")\n",
                "print(f\"  F1 Score: {f1_leak:.4f}\")\n",
                "print(\"  (Overly optimistic due to leakage!)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# \u2705 CLEAN PIPELINE: Split FIRST, then preprocess\n",
                "# ============================================================\n",
                "print(\"=\"*60)\n",
                "print(\"\u2705 CLEAN PIPELINE (using sklearn Pipeline)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Split FIRST\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X_df, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# Create a pipeline (fit only on train!)\n",
                "clean_pipeline = Pipeline([\n",
                "    ('imputer', SimpleImputer(strategy='mean')),\n",
                "    ('scaler', StandardScaler()),\n",
                "    ('model', RandomForestClassifier(n_estimators=100, random_state=42))\n",
                "])\n",
                "\n",
                "# .fit() fits ALL steps on training data only\n",
                "clean_pipeline.fit(X_train, y_train)\n",
                "\n",
                "# .predict() transforms test data using train-fitted params\n",
                "y_pred_clean = clean_pipeline.predict(X_test)\n",
                "\n",
                "acc_clean = accuracy_score(y_test, y_pred_clean)\n",
                "f1_clean = f1_score(y_test, y_pred_clean)\n",
                "print(f\"  Accuracy: {acc_clean:.4f}\")\n",
                "print(f\"  F1 Score: {f1_clean:.4f}\")\n",
                "print(\"  (Honest estimate of real-world performance)\")\n",
                "\n",
                "# Compare\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"COMPARISON\")\n",
                "print(\"=\"*60)\n",
                "print(f\"{'Metric':<12} {'Leaky':<12} {'Clean':<12} {'Difference':<12}\")\n",
                "print(f\"{'Accuracy':<12} {acc_leak:<12.4f} {acc_clean:<12.4f} {acc_leak-acc_clean:+.4f}\")\n",
                "print(f\"{'F1 Score':<12} {f1_leak:<12.4f} {f1_clean:<12.4f} {f1_leak-f1_clean:+.4f}\")\n",
                "print(\"\\n>>> The leaky pipeline appears better, but it's a LIE.\")\n",
                "print(\">>> In production, the clean pipeline will perform as expected.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# DEMO: Target Leakage Detection\n",
                "# ============================================================\n",
                "print(\"=\"*60)\n",
                "print(\"TARGET LEAKAGE DETECTION\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Create a dataset with a leaky feature\n",
                "n = 5000\n",
                "df = pd.DataFrame({\n",
                "    'age': np.random.randint(18, 80, n),\n",
                "    'income': np.random.normal(50000, 15000, n),\n",
                "    'credit_score': np.random.randint(300, 850, n),\n",
                "    'loan_amount': np.random.uniform(1000, 50000, n),\n",
                "})\n",
                "\n",
                "# Target: loan default (1 = defaulted)\n",
                "df['defaulted'] = ((df['credit_score'] < 500) & \n",
                "                   (df['loan_amount'] > 20000)).astype(int)\n",
                "\n",
                "# LEAKY FEATURE: collection_agency_id (only assigned AFTER default)\n",
                "df['collection_agency_id'] = np.where(\n",
                "    df['defaulted'] == 1,\n",
                "    np.random.choice(['AgencyA', 'AgencyB', 'AgencyC'], n),\n",
                "    'None'\n",
                ")\n",
                "\n",
                "# Detection: Check feature-target correlation\n",
                "print(\"\\nFeature-target correlations (suspicious if too high):\")\n",
                "for col in ['age', 'income', 'credit_score', 'loan_amount', 'collection_agency_id']:\n",
                "    if df[col].dtype == 'object':\n",
                "        # For categorical: check if it perfectly predicts target\n",
                "        is_none = (df[col] == 'None').astype(int)\n",
                "        corr = is_none.corr(df['defaulted'])\n",
                "        flag = ' \ud83d\udea9 LEAK!' if abs(corr) > 0.9 else ''\n",
                "    else:\n",
                "        corr = df[col].corr(df['defaulted'])\n",
                "        flag = ' \ud83d\udea9 LEAK!' if abs(corr) > 0.9 else ''\n",
                "    print(f\"  {col:<25} corr={corr:+.3f}{flag}\")\n",
                "\n",
                "print(\"\\n>>> collection_agency_id has near-perfect correlation with target!\")\n",
                "print(\">>> This feature would NOT exist at prediction time. Remove it.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# DEMO: Temporal Leakage - Walk-Forward Validation\n",
                "# ============================================================\n",
                "print(\"=\"*60)\n",
                "print(\"TEMPORAL SPLIT: Walk-Forward Validation\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Simulate time-series data\n",
                "dates = pd.date_range('2023-01-01', periods=365, freq='D')\n",
                "ts_df = pd.DataFrame({\n",
                "    'date': dates,\n",
                "    'feature_1': np.random.randn(365).cumsum(),\n",
                "    'feature_2': np.random.randn(365),\n",
                "    'target': (np.random.randn(365).cumsum() > 0).astype(int)\n",
                "})\n",
                "\n",
                "# Temporal split: first 80% train, last 20% test\n",
                "split_idx = int(len(ts_df) * 0.8)\n",
                "train_ts = ts_df[:split_idx]\n",
                "test_ts = ts_df[split_idx:]\n",
                "\n",
                "print(f\"Train period: {train_ts['date'].min().date()} to {train_ts['date'].max().date()}\")\n",
                "print(f\"Test period:  {test_ts['date'].min().date()} to {test_ts['date'].max().date()}\")\n",
                "print(f\"\\nTrain: {len(train_ts)} days | Test: {len(test_ts)} days\")\n",
                "print(\"\\n>>> No future data leaks into training!\")\n",
                "\n",
                "# Walk-forward validation\n",
                "print(\"\\nWalk-Forward Cross-Validation Folds:\")\n",
                "print(\"  Fold 1: Train [Jan-Mar] \u2192 Test [Apr]\")\n",
                "print(\"  Fold 2: Train [Jan-Apr] \u2192 Test [May]\")\n",
                "print(\"  Fold 3: Train [Jan-May] \u2192 Test [Jun]\")\n",
                "print(\"  ...\")\n",
                "print(\"\\n>>> Each fold only uses past data to train!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Leakage Detection Checklist <a id='7-checklist'></a>\n",
                "\n",
                "```\n",
                "  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "  \u2502       LEAKAGE DETECTION CHECKLIST              \u2502\n",
                "  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
                "  \u2502 \u2610 Suspiciously high accuracy (>95%)?            \u2502\n",
                "  \u2502 \u2610 Any feature with >0.9 target correlation?      \u2502\n",
                "  \u2502 \u2610 Preprocessing done BEFORE train/test split?    \u2502\n",
                "  \u2502 \u2610 Using future info for time-series data?        \u2502\n",
                "  \u2502 \u2610 Test performance >> cross-validation?          \u2502\n",
                "  \u2502 \u2610 SMOTE/oversampling applied before splitting?   \u2502\n",
                "  \u2502 \u2610 Feature available at prediction time?          \u2502\n",
                "  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "```\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Exercises <a id='8-exercises'></a>\n",
                "\n",
                "### Exercise 1: Find the Leak\n",
                "Given a medical dataset with columns `[age, blood_pressure, cholesterol, diagnosis_code, treatment_outcome]` where the task is to predict `treatment_outcome` \u2014 which feature is likely leaky and why?\n",
                "\n",
                "### Exercise 2: Fix the Pipeline\n",
                "Refactor this leaky code using `sklearn.pipeline.Pipeline`:\n",
                "```python\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)  # Leaky!\n",
                "X_train, X_test = train_test_split(X_scaled)\n",
                "model.fit(X_train, y_train)\n",
                "```\n",
                "\n",
                "### Exercise 3: Cross-Validation Without Leakage\n",
                "Implement k-fold cross-validation that correctly handles scaling inside each fold using `cross_val_score` with a Pipeline.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Interview Preparation <a id='9-interview'></a>\n",
                "\n",
                "### Q1: \"What is data leakage? Give me a real example.\"\n",
                "\n",
                "**Answer:**  \n",
                "\"Data leakage is when information that wouldn\u2019t be available at prediction time is used during training. Example: predicting hospital readmission using discharge notes \u2014 those notes only exist AFTER the discharge decision, so they encode the outcome.\n",
                "\n",
                "The telltale sign is **suspiciously high training/validation accuracy that drops in production**.\"\n",
                "\n",
                "---\n",
                "\n",
                "### Q2: \"How do you prevent train-test contamination in preprocessing?\"\n",
                "\n",
                "**Answer:**  \n",
                "\"Use `sklearn.pipeline.Pipeline`. It ensures all preprocessing steps (imputing, scaling, encoding) are **fit only on training data**. When you call `pipeline.predict(X_test)`, it applies the train-fitted transformers without re-fitting.\n",
                "\n",
                "Key rules: split FIRST, then preprocess. Never call `.fit()` on test data. For cross-validation, use `cross_val_score` with a Pipeline.\"\n",
                "\n",
                "---\n",
                "\n",
                "### Q3: \"How would you detect leakage in an existing model?\"\n",
                "\n",
                "**Answer:**  \n",
                "\"Red flags: (1) Test accuracy suspiciously close to 100%, (2) Large gap between CV and production performance, (3) Feature has near-perfect correlation with target. Detection: examine feature importance \u2014 if one feature dominates, check if it\u2019s available at prediction time. Also verify preprocessing happens after splitting.\"\n",
                "\n",
                "---\n",
                "\n",
                "### Q4: \"How do you split time-series data without leakage?\"\n",
                "\n",
                "**Answer:**  \n",
                "\"Never use random splits for time-series. Use **temporal splitting**: train on past data, test on future data. For cross-validation, use **walk-forward** (expanding window): train on [Jan-Mar], test on [Apr]; train on [Jan-Apr], test on [May]; etc. `sklearn.TimeSeriesSplit` implements this.\"\n",
                "\n",
                "---\n",
                "\n",
                "### Q5: \"You built a model with 98% accuracy but it performs at 60% in production. What happened?\"\n",
                "\n",
                "**Answer:**  \n",
                "\"Almost certainly data leakage. I\u2019d investigate:\n",
                "1. **Target leakage**: Is any feature derived from the target?\n",
                "2. **Train-test contamination**: Was preprocessing done before splitting?\n",
                "3. **Temporal leakage**: Was future data used to build features?\n",
                "4. **Distribution shift**: Has the production data distribution changed?\n",
                "\n",
                "First fix: rebuild with a Pipeline, verify no leaky features, add post-load validation. Then compare dev vs production metrics.\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## \ud83c\udf93 Key Takeaways\n",
                "\n",
                "1. **Leakage is the most insidious ML bug** \u2014 it makes your model look great in dev, then fail in production\n",
                "2. **Three types**: Target leakage, train-test contamination, temporal leakage\n",
                "3. **Always split FIRST**, then preprocess\n",
                "4. **Use `sklearn.Pipeline`** to prevent contamination automatically\n",
                "5. **For time-series**: temporal splits only, never random\n",
                "6. **Suspect leakage** whenever accuracy is too good to be true\n",
                "\n",
                "---\n",
                "\n",
                "\u27a1\ufe0f **Next Lesson**: [Lesson 5: Feature Stores with Feast](./lesson_05_feature_stores_feast.ipynb)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}