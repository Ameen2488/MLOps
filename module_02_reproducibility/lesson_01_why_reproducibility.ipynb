{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 1: Why Reproducibility Matters in ML\n",
                "\n",
                "**Module 2: Reproducibility & Versioning**  \n",
                "**Estimated Time**: 2-3 hours  \n",
                "**Difficulty**: Intermediate\n",
                "\n",
                "---\n",
                "\n",
                "## üéØ Learning Objectives\n",
                "\n",
                "By the end of this lesson, you will:\n",
                "\n",
                "‚úÖ Understand what reproducibility means in ML context  \n",
                "‚úÖ Know why reproducibility is critical for production systems  \n",
                "‚úÖ Identify sources of non-determinism in ML workflows  \n",
                "‚úÖ Answer senior-level interview questions on reproducibility  \n",
                "‚úÖ Implement deterministic ML pipelines  \n",
                "\n",
                "---\n",
                "\n",
                "## üìö Table of Contents\n",
                "\n",
                "1. [What is Reproducibility?](#1-what-is-reproducibility)\n",
                "2. [Why Reproducibility Matters](#2-why-reproducibility-matters)\n",
                "3. [Real-World Reproducibility Failures](#3-real-world-failures)\n",
                "4. [Sources of Non-Determinism](#4-sources-of-non-determinism)\n",
                "5. [Reproducibility vs Replicability](#5-reproducibility-vs-replicability)\n",
                "6. [Levels of Reproducibility](#6-levels-of-reproducibility)\n",
                "7. [Hands-On: Building Deterministic Pipelines](#7-hands-on)\n",
                "8. [Interview Preparation](#8-interview-prep)\n",
                "9. [Key Takeaways](#9-key-takeaways)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. What is Reproducibility? {#1-what-is-reproducibility}\n",
                "\n",
                "### Definition\n",
                "\n",
                "**Reproducibility** in machine learning means:\n",
                "\n",
                "> *\"Given the same code, data, and environment, running an ML experiment multiple times should produce the same results.\"*\n",
                "\n",
                "### Why This is Challenging in ML\n",
                "\n",
                "Unlike traditional software where `f(x)` always returns the same output for the same input:\n",
                "\n",
                "```python\n",
                "# Traditional Software - Deterministic\n",
                "def add(a, b):\n",
                "    return a + b\n",
                "\n",
                "add(2, 3)  # Always returns 5\n",
                "```\n",
                "\n",
                "ML systems involve:\n",
                "- **Random initialization** (neural network weights)\n",
                "- **Stochastic algorithms** (SGD, dropout, data shuffling)\n",
                "- **Hardware differences** (GPU vs CPU, floating-point precision)\n",
                "- **Distributed training** (parallel random number generation)\n",
                "- **Data dependencies** (changing datasets)\n",
                "- **Library versions** (different implementations)\n",
                "\n",
                "```python\n",
                "# ML - Can be Non-Deterministic\n",
                "model.fit(X_train, y_train)\n",
                "predictions = model.predict(X_test)\n",
                "# Might produce different results each run!\n",
                "```\n",
                "\n",
                "### üéôÔ∏è Senior DS Interview Question:\n",
                "\n",
                "**Q: \"Your model achieves 95% accuracy today but only 93% when a colleague runs it tomorrow. What could be wrong?\"**\n",
                "\n",
                "<details>\n",
                "<summary>Click to see Model Answer</summary>\n",
                "\n",
                "**Answer Framework**:\n",
                "\n",
                "1. **Random seeds not set**: Different train/test splits, weight initialization\n",
                "2. **Data changed**: New data added, data pipeline issue\n",
                "3. **Environment differences**: Library versions, hardware (GPU/CPU)\n",
                "4. **Training order**: Shuffling, batch ordering\n",
                "5. **Non-deterministic operations**: GPU operations, async processing\n",
                "\n",
                "**What the interviewer wants to hear**:\n",
                "- Systematic debugging approach\n",
                "- Understanding of ML-specific reproducibility challenges\n",
                "- Knowledge of solutions (seed fixing, environment management)\n",
                "- Production awareness\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Why Reproducibility Matters {#2-why-reproducibility-matters}\n",
                "\n",
                "### Critical Reasons\n",
                "\n",
                "#### 1. **Debugging and Error Analysis** üêõ\n",
                "\n",
                "Without reproducibility:\n",
                "- Can't reliably debug\n",
                "- Can't verify fixes\n",
                "- Can't trace errors\n",
                "\n",
                "**Real Scenario**: Model performance drops in production. Without reproducibility, you can't:\n",
                "- Recreate the exact training conditions\n",
                "- Test if the issue exists in the original model\n",
                "- Verify if your fix actually works\n",
                "\n",
                "#### 2. **Collaboration and Knowledge Transfer** üë•\n",
                "\n",
                "In a team:\n",
                "- Other data scientists need to reproduce your results\n",
                "- Code reviews require reproducible experiments\n",
                "- Onboarding new team members\n",
                "- Handoffs between research and production teams\n",
                "\n",
                "#### 3. **Regulatory Compliance** ‚öñÔ∏è\n",
                "\n",
                "Industries that REQUIRE reproducibility:\n",
                "- **Healthcare (FDA)**: Medical device approval requires reproducible results\n",
                "- **Finance**: Model validation for risk assessment\n",
                "- **Autonomous Vehicles**: Safety-critical systems\n",
                "- **Insurance**: Actuarial model audits\n",
                "\n",
                "**Legal implications**: Can't deploy models you can't reproduce!\n",
                "\n",
                "#### 4. **Model Versioning and Rollback** üîÑ\n",
                "\n",
                "Production requirements:\n",
                "- Deploy model v1.2 instead of v1.3\n",
                "- Roll back to previous best-performing model\n",
                "- Compare models trained on different data periods\n",
                "- A/B testing requires exact model recreation\n",
                "\n",
                "#### 5. **Scientific Integrity** üî¨\n",
                "\n",
                "For research:\n",
                "- Publishing papers requires reproducible results\n",
                "- Peer review needs verification\n",
                "- Building on others' work\n",
                "\n",
                "#### 6. **Cost and Time Savings** üí∞\n",
                "\n",
                "**Real Numbers**:\n",
                "- Training large models can cost **$100,000+ per run**\n",
                "- GPT-3 training: ~$4-12 million\n",
                "- Can't afford to \"just retrain\" if results aren't reproducible\n",
                "\n",
                "### üéôÔ∏è Senior DS Interview Question:\n",
                "\n",
                "**Q: \"Why should a company invest time in making ML pipelines reproducible?\"**\n",
                "\n",
                "<details>\n",
                "<summary>Click to see Model Answer</summary>\n",
                "\n",
                "**Answer (Prioritize business impact)**:\n",
                "\n",
                "1. **Risk Mitigation**: \n",
                "   - Regulatory compliance (healthcare, finance)\n",
                "   - Audit trails for model decisions\n",
                "   - Legal defensibility\n",
                "\n",
                "2. **Cost Reduction**:\n",
                "   - Avoid expensive retraining due to uncertainty\n",
                "   - Faster debugging (hours vs weeks)\n",
                "   - Reduce wasted compute resources\n",
                "\n",
                "3. **Team Velocity**:\n",
                "   - Faster onboarding\n",
                "   - Reliable collaboration\n",
                "   - Confident deployments\n",
                "\n",
                "4. **Production Reliability**:\n",
                "   - Safe rollbacks\n",
                "   - Verified deployments\n",
                "   - Traceable model lineage\n",
                "\n",
                "**Quantify when possible**: \"In my experience, reproducibility reduced debugging time from 2-3 days to 2-3 hours.\"\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Real-World Reproducibility Failures {#3-real-world-failures}\n",
                "\n",
                "### Case Study 1: Healthcare AI Disaster\n",
                "\n",
                "**Scenario**: Hospital deploys COVID-19 diagnosis model\n",
                "\n",
                "**Problem**:\n",
                "- Model showed 97% accuracy in research\n",
                "- Same code in production showed 78% accuracy\n",
                "- Couldn't reproduce original results\n",
                "\n",
                "**Root Cause**:\n",
                "- Different image preprocessing (library version change)\n",
                "- Training data wasn't versioned\n",
                "- Random seed not set for data split\n",
                "\n",
                "**Impact**: Model pulled from production, delayed patient care\n",
                "\n",
                "### Case Study 2: Financial Trading Model\n",
                "\n",
                "**Scenario**: Quant team develops profitable trading strategy\n",
                "\n",
                "**Problem**:\n",
                "- Backtest showed 45% annual return\n",
                "- Live trading showed -12% return\n",
                "- Couldn't reproduce backtest results exactly\n",
                "\n",
                "**Root Cause**:\n",
                "- Temporal data leakage (using future information)\n",
                "- Different data preprocessing in backtest vs production\n",
                "- Non-reproducible train/test splits\n",
                "\n",
                "**Impact**: $2M+ losses before model was stopped\n",
                "\n",
                "### Case Study 3: Research Paper Retraction\n",
                "\n",
                "**Scenario**: Top-tier ML conference paper\n",
                "\n",
                "**Problem**:\n",
                "- Claimed state-of-the-art results\n",
                "- Other researchers couldn't reproduce\n",
                "- Authors also couldn't reproduce their own results\n",
                "\n",
                "**Root Cause**:\n",
                "- Hyperparameter search not documented\n",
                "- \"Lucky\" random seed selection\n",
                "- Data preprocessing steps missing\n",
                "\n",
                "**Impact**: Paper retracted, reputational damage\n",
                "\n",
                "### Lessons Learned\n",
                "\n",
                "1. **Version everything**: Code, data, environment, configs\n",
                "2. **Document everything**: Random seeds, preprocessing, hyperparameters\n",
                "3. **Test reproducibility**: Before claiming results\n",
                "4. **Automate**: Manual steps introduce variability"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Sources of Non-Determinism in ML {#4-sources-of-non-determinism}\n",
                "\n",
                "### Category 1: Random Number Generation\n",
                "\n",
                "**Where it appears**:\n",
                "- Weight initialization\n",
                "- Data shuffling\n",
                "- Train/test splits\n",
                "- Dropout\n",
                "- Data augmentation\n",
                "- Stochastic algorithms (SGD)\n",
                "\n",
                "**Solution**: Set random seeds\n",
                "\n",
                "### Category 2: Hardware & Computation\n",
                "\n",
                "**Where it appears**:\n",
                "- Float point precision (CPU vs GPU)\n",
                "- Parallel reduction order\n",
                "- GPU non-deterministic CUDA operations\n",
                "- Multi-threading race conditions\n",
                "\n",
                "**Solution**: Use deterministic modes, specific hardware\n",
                "\n",
                "### Category 3: External Dependencies\n",
                "\n",
                "**Where it appears**:\n",
                "- Library version changes\n",
                "- OS differences\n",
                "- Data source changes\n",
                "- API updates\n",
                "\n",
                "**Solution**: Version pinning, containerization\n",
                "\n",
                "### Category 4: Data\n",
                "\n",
                "**Where it appears**:\n",
                "- Datasets updated\n",
                "- Different data queries\n",
                "- Data pipeline changes\n",
                "- Temporal dependencies\n",
                "\n",
                "**Solution**: Data versioning (DVC)\n",
                "\n",
                "### Category 5: Human Factors\n",
                "\n",
                "**Where it appears**:\n",
                "- Manual data cleaning\n",
                "- Exploratory notebooks\n",
                "- Undocumented hyperparameter tuning\n",
                "- \"Let me try changing this...\"\n",
                "\n",
                "**Solution**: Automation, documentation, MLOps tools"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Reproducibility vs Replicability {#5-reproducibility-vs-replicability}\n",
                "\n",
                "### Important Distinction\n",
                "\n",
                "| Aspect | Reproducibility | Replicability |\n",
                "|--------|----------------|---------------|\n",
                "| **Definition** | Same team, same setup, same results | Different team, different setup, similar results |\n",
                "| **Code** | Exact same code | Different implementation |\n",
                "| **Data** | Exact same data | Similar/different data |\n",
                "| **Environment** | Exact same environment | Different environment |\n",
                "| **Goal** | Verify specific results | Validate general findings |\n",
                "| **Difficulty** | Easier (should be standard) | Harder (research validation) |\n",
                "\n",
                "### Example\n",
                "\n",
                "**Reproducibility**:\n",
                "```\n",
                "Team A, Jan 2024: Train BERT ‚Üí 94.2% accuracy\n",
                "Team A, Feb 2024: Run same code ‚Üí 94.2% accuracy ‚úÖ\n",
                "```\n",
                "\n",
                "**Replicability**:\n",
                "```\n",
                "Team A: Train BERT on Dataset X ‚Üí 94.2% accuracy\n",
                "Team B: Train different architecture on Dataset Y ‚Üí 94.5% accuracy ‚úÖ\n",
                "(Confirms that transformer-based models work well for this task type)\n",
                "```\n",
                "\n",
                "### In Production ML\n",
                "\n",
                "**You NEED reproducibility**:\n",
                "- Must recreate exact model for deployment\n",
                "- Must debug specific issues\n",
                "- Must comply with regulations\n",
                "\n",
                "**Replicability is a bonus**:\n",
                "- Validates approach\n",
                "- Research contribution\n",
                "- Scientific rigor"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Levels of Reproducibility {#6-levels-of-reproducibility}\n",
                "\n",
                "### Level 0: No Reproducibility ‚ùå\n",
                "\n",
                "**Characteristics**:\n",
                "- No version control\n",
                "- No documentation\n",
                "- Manual steps everywhere\n",
                "- Different results every run\n",
                "\n",
                "**Example**:\n",
                "```python\n",
                "# notebook_final_v3_really_final.ipynb\n",
                "# Run cells randomly\n",
                "# No seeds\n",
                "# Magic numbers everywhere\n",
                "```\n",
                "\n",
                "**Impact**: Can't use in production\n",
                "\n",
                "### Level 1: Code Reproducibility ‚ö†Ô∏è\n",
                "\n",
                "**Characteristics**:\n",
                "- Code in Git\n",
                "- Can run scripts\n",
                "- Still different results\n",
                "\n",
                "**Missing**: Seeds, environment, data versioning\n",
                "\n",
                "### Level 2: Environment Reproducibility üü°\n",
                "\n",
                "**Characteristics**:\n",
                "- Requirements.txt / environment.yml\n",
                "- Docker containers\n",
                "- Closer to reproducible\n",
                "\n",
                "**Missing**: Data versioning, seed management\n",
                "\n",
                "### Level 3: Full Reproducibility ‚úÖ\n",
                "\n",
                "**Characteristics**:\n",
                "- Code versioned (Git)\n",
                "- Data versioned (DVC)\n",
                "- Environment fixed (Docker)\n",
                "- Seeds set\n",
                "- Experiments tracked (MLflow/W&B)\n",
                "- Automated pipelines\n",
                "\n",
                "**Result**: Bit-for-bit identical results\n",
                "\n",
                "### Level 4: Production Reproducibility üèÜ\n",
                "\n",
                "**Everything from Level 3 PLUS**:\n",
                "- CI/CD pipelines\n",
                "- Automated testing\n",
                "- Model registry\n",
                "- Deployment automation\n",
                "- Monitoring and alerts\n",
                "- Rollback capabilities\n",
                "\n",
                "**This is the goal of this program!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Hands-On: Building Deterministic Pipelines {#7-hands-on}\n",
                "\n",
                "### Exercise 1: The Problem - Non-Deterministic Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset created:\n",
                        "Samples: 1000, Features: 20\n"
                    ]
                }
            ],
            "source": [
                "# Import libraries\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.datasets import make_classification\n",
                "\n",
                "# Create synthetic dataset\n",
                "X, y = make_classification(\n",
                "    n_samples=1000,\n",
                "    n_features=20,\n",
                "    n_informative=15,\n",
                "    n_redundant=5,\n",
                "    n_classes=2\n",
                ")\n",
                "\n",
                "print(\"Dataset created:\")\n",
                "print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Non-reproducible results (run multiple times):\n",
                        "Run 1: Accuracy = 0.8900\n",
                        "Run 2: Accuracy = 0.8700\n",
                        "Run 3: Accuracy = 0.8900\n",
                        "Run 4: Accuracy = 0.8850\n",
                        "Run 5: Accuracy = 0.9400\n",
                        "\n",
                        "‚ö†Ô∏è Notice: Results are different every time!\n"
                    ]
                }
            ],
            "source": [
                "# NON-REPRODUCIBLE VERSION\n",
                "# Run this cell multiple times - you'll get different results!\n",
                "\n",
                "def train_model_non_reproducible():\n",
                "    \"\"\"Train model WITHOUT setting seeds - results will vary.\"\"\"\n",
                "    \n",
                "    # Split data (no random_state)\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X, y, test_size=0.2\n",
                "    )\n",
                "    \n",
                "    # Train model (no random_state)\n",
                "    model = RandomForestClassifier(n_estimators=100)\n",
                "    model.fit(X_train, y_train)\n",
                "    \n",
                "    # Evaluate\n",
                "    y_pred = model.predict(X_test)\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    \n",
                "    return accuracy\n",
                "\n",
                "# Run 5 times\n",
                "print(\"Non-reproducible results (run multiple times):\")\n",
                "for i in range(5):\n",
                "    acc = train_model_non_reproducible()\n",
                "    print(f\"Run {i+1}: Accuracy = {acc:.4f}\")\n",
                "\n",
                "print(\"\\n‚ö†Ô∏è Notice: Results are different every time!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise 2: The Solution - Deterministic Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reproducible results (run multiple times):\n",
                        "Run 1: Accuracy = 0.9150\n",
                        "Run 2: Accuracy = 0.9150\n",
                        "Run 3: Accuracy = 0.9150\n",
                        "Run 4: Accuracy = 0.9150\n",
                        "Run 5: Accuracy = 0.9150\n",
                        "\n",
                        "‚úÖ All results identical: True\n",
                        "Standard deviation: 0.0000000000\n"
                    ]
                }
            ],
            "source": [
                "# REPRODUCIBLE VERSION\n",
                "# Run this cell multiple times - same results!\n",
                "\n",
                "def set_seeds(seed=42):\n",
                "    \"\"\"Set all random seeds for reproducibility.\"\"\"\n",
                "    np.random.seed(seed)\n",
                "    # Add: random.seed(seed), torch.manual_seed(seed), etc.\n",
                "\n",
                "def train_model_reproducible(seed=42):\n",
                "    \"\"\"Train model WITH seeds - results will be identical.\"\"\"\n",
                "    \n",
                "    # Set all seeds\n",
                "    set_seeds(seed)\n",
                "    \n",
                "    # Split data (with random_state)\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X, y, test_size=0.2, random_state=seed\n",
                "    )\n",
                "    \n",
                "    # Train model (with random_state)\n",
                "    model = RandomForestClassifier(\n",
                "        n_estimators=100,\n",
                "        random_state=seed\n",
                "    )\n",
                "    model.fit(X_train, y_train)\n",
                "    \n",
                "    # Evaluate\n",
                "    y_pred = model.predict(X_test)\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    \n",
                "    return accuracy, model\n",
                "\n",
                "# Run 5 times with same seed\n",
                "print(\"Reproducible results (run multiple times):\")\n",
                "accuracies = []\n",
                "for i in range(5):\n",
                "    acc, _ = train_model_reproducible(seed=42)\n",
                "    accuracies.append(acc)\n",
                "    print(f\"Run {i+1}: Accuracy = {acc:.4f}\")\n",
                "\n",
                "print(f\"\\n‚úÖ All results identical: {len(set(accuracies)) == 1}\")\n",
                "print(f\"Standard deviation: {np.std(accuracies):.10f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise 3: Multi-Library Seed Setting (PyTorch Example)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ PyTorch seeds set\n",
                        "‚ÑπÔ∏è TensorFlow not available\n",
                        "\n",
                        "‚úÖ All available seeds set to 42\n"
                    ]
                }
            ],
            "source": [
                "# Complete seed setting for deep learning projects\n",
                "\n",
                "import random\n",
                "import os\n",
                "\n",
                "def set_all_seeds(seed=42):\n",
                "    \"\"\"\n",
                "    Set seeds for reproducibility across all libraries.\n",
                "    Use this at the start of every ML script/notebook.\n",
                "    \"\"\"\n",
                "    # Python random\n",
                "    random.seed(seed)\n",
                "    \n",
                "    # NumPy\n",
                "    np.random.seed(seed)\n",
                "    \n",
                "    # PyTorch (if using)\n",
                "    try:\n",
                "        import torch\n",
                "        torch.manual_seed(seed)\n",
                "        torch.cuda.manual_seed(seed)\n",
                "        torch.cuda.manual_seed_all(seed)  # multi-GPU\n",
                "        \n",
                "        # Additional PyTorch settings for reproducibility\n",
                "        torch.backends.cudnn.deterministic = True\n",
                "        torch.backends.cudnn.benchmark = False\n",
                "        \n",
                "        print(\"‚úÖ PyTorch seeds set\")\n",
                "    except ImportError:\n",
                "        print(\"‚ÑπÔ∏è PyTorch not available\")\n",
                "    \n",
                "    # TensorFlow (if using)\n",
                "    try:\n",
                "        import tensorflow as tf\n",
                "        tf.random.set_seed(seed)\n",
                "        os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
                "        print(\"‚úÖ TensorFlow seeds set\")\n",
                "    except ImportError:\n",
                "        print(\"‚ÑπÔ∏è TensorFlow not available\")\n",
                "    \n",
                "    # Environment variable for hash seed\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    \n",
                "    print(f\"\\n‚úÖ All available seeds set to {seed}\")\n",
                "\n",
                "# Use at start of every project\n",
                "set_all_seeds(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üéØ Practice Exercise\n",
                "\n",
                "**Your Turn**: Create a reproducible training pipeline\n",
                "\n",
                "**Requirements**:\n",
                "1. Load a dataset (use sklearn.datasets)\n",
                "2. Split into train/validation/test sets\n",
                "3. Train a model\n",
                "4. Ensure it's fully reproducible\n",
                "5. Verify by running 3 times\n",
                "\n",
                "**Bonus**: Add logging of all hyperparameters and results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# YOUR CODE HERE\n",
                "# Remember:\n",
                "# 1. Set all seeds\n",
                "# 2. Use random_state parameters\n",
                "# 3. Document your approach\n",
                "\n",
                "def your_reproducible_pipeline():\n",
                "    \"\"\"Complete this function.\"\"\"\n",
                "    pass\n",
                "\n",
                "# Test reproducibility\n",
                "# Run 3 times and verify identical results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Interview Preparation {#8-interview-prep}\n",
                "\n",
                "### Common Senior DS Interview Questions on Reproducibility\n",
                "\n",
                "#### Question 1: Conceptual Understanding\n",
                "\n",
                "**Q: \"What does reproducibility mean in the context of ML, and why is it important?\"**\n",
                "\n",
                "**Model Answer**:\n",
                "- Definition: Same inputs ‚Üí same outputs\n",
                "- Challenges: Random processes, hardware, versions\n",
                "- Importance: Debugging, compliance, deployment, collaboration\n",
                "- Real example from your experience\n",
                "\n",
                "---\n",
                "\n",
                "#### Question 2: Technical Implementation\n",
                "\n",
                "**Q: \"How do you ensure your ML experiments are reproducible?\"**\n",
                "\n",
                "**Model Answer** (Use this framework):\n",
                "\n",
                "1. **Code**: Git version control, tagged releases\n",
                "2. **Data**: DVC for data versioning\n",
                "3. **Environment**: Docker containers, requirements.txt\n",
                "4. **Seeds**: Set random seeds (numpy, torch, tf)\n",
                "5. **Experiments**: MLflow/W&B tracking\n",
                "6. **Configs**: YAML files for all hyperparameters\n",
                "7. **Testing**: Automated reproducibility tests\n",
                "\n",
                "**Code snippet** (have this ready):\n",
                "```python\n",
                "def ensure_reproducibility(seed=42):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "```\n",
                "\n",
                "---\n",
                "\n",
                "#### Question 3: Debugging Scenario\n",
                "\n",
                "**Q: \"Your model works on your laptop but gives different results on the production server. How do you debug this?\"**\n",
                "\n",
                "**Model Answer** (Systematic approach):\n",
                "\n",
                "1. **Check seeds**: Are random seeds set?\n",
                "2. **Check data**: Is it the exact same data? Same version?\n",
                "3. **Check environment**: Library versions match? requirements.txt?\n",
                "4. **Check hardware**: CPU vs GPU differences? Floating point precision?\n",
                "5. **Check preprocessing**: Same preprocessing steps? Same order?\n",
                "6. **Check model**: Exact same model architecture? Same weights?\n",
                "\n",
                "**Tools I'd use**:\n",
                "- DVC for data comparison\n",
                "- Docker to ensure environment parity\n",
                "- MLflow to compare experiment configs\n",
                "- Unit tests for data preprocessing\n",
                "\n",
                "---\n",
                "\n",
                "#### Question 4: Trade-offs\n",
                "\n",
                "**Q: \"What are the trade-offs of enforcing strict reproducibility?\"**\n",
                "\n",
                "**Model Answer** (Show balanced thinking):\n",
                "\n",
                "**Benefits**:\n",
                "- Reliable debugging\n",
                "- Production confidence\n",
                "- Regulatory compliance\n",
                "\n",
                "**Costs**:\n",
                "- **Performance**: Deterministic ops can be slower (e.g., CUDA)\n",
                "- **Flexibility**: Can't easily try different random initializations\n",
                "- **Overhead**: Time spent on reproducibility infrastructure\n",
                "\n",
                "**When to prioritize**:\n",
                "- Production models: Always\n",
                "- Research exploration: Maybe not\n",
                "- Regulated industries: Must have\n",
                "\n",
                "---\n",
                "\n",
                "#### Question 5: System Design\n",
                "\n",
                "**Q: \"Design a system that ensures reproducibility for a team of 20 data scientists.\"**\n",
                "\n",
                "**Model Answer** (Architecture thinking):\n",
                "\n",
                "**Components**:\n",
                "1. **Centralized Git repos**: All code versioned\n",
                "2. **DVC server**: Shared data versioning\n",
                "3. **Docker registry**: Standardized environments\n",
                "4. **MLflow server**: Central experiment tracking\n",
                "5. **CI/CD**: Automated reproducibility tests\n",
                "6. **Templates**: Cookiecutter project templates with seeds\n",
                "\n",
                "**Processes**:\n",
                "- Code review checklist (seeds set?)\n",
                "- Pre-deployment validation (reproducible?)\n",
                "- Documentation requirements\n",
                "- Training for team on best practices"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Key Takeaways {#9-key-takeaways}\n",
                "\n",
                "### What You Should Remember\n",
                "\n",
                "1. **Reproducibility is non-negotiable for production ML**\n",
                "   - Debugging requires it\n",
                "   - Compliance demands it\n",
                "   - Deployment depends on it\n",
                "\n",
                "2. **Sources of non-determinism are everywhere**\n",
                "   - Random number generation\n",
                "   - Hardware differences\n",
                "   - Library versions\n",
                "   - Data changes\n",
                "\n",
                "3. **Solutions exist and are straightforward**\n",
                "   - Set seeds everywhere\n",
                "   - Version code, data, environment\n",
                "   - Use MLOps tools (DVC, MLflow, Docker)\n",
                "   - Automate and test\n",
                "\n",
                "4. **Reproducibility != Replicability**\n",
                "   - Reproducibility: Exact same results\n",
                "   - Replicability: Similar results, different setup\n",
                "\n",
                "5. **There are levels of reproducibility**\n",
                "   - Aim for Level 4: Production reproducibility\n",
                "   - Requires tools and processes\n",
                "\n",
                "### For Your Interview\n",
                "\n",
                "**Be ready to discuss**:\n",
                "- Why reproducibility matters (business value)\n",
                "- How you implement it (technical details)\n",
                "- Real examples from your experience\n",
                "- Trade-offs and when to prioritize\n",
                "\n",
                "**Have code examples ready**:\n",
                "- Seed setting functions\n",
                "- Reproducible training pipelines\n",
                "- Environment management\n",
                "\n",
                "---\n",
                "\n",
                "## üìö Further Reading\n",
                "\n",
                "- [Hidden Technical Debt in ML Systems](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)\n",
                "- [Reproducibility in ML](https://arxiv.org/abs/2003.12206)\n",
                "- [Daily Dose of DS - Part 3](https://www.dailydoseofds.com/mlops-crash-course-part-3/)\n",
                "\n",
                "---\n",
                "\n",
                "## ‚û°Ô∏è Next Lesson\n",
                "\n",
                "**[Lesson 2: Git and DVC Fundamentals](./lesson_02_git_and_dvc.ipynb)**\n",
                "\n",
                "Learn how to version control your code AND data for complete reproducibility.\n",
                "\n",
                "---\n",
                "\n",
                "**Congratulations! You now understand why reproducibility is critical and how to implement it.** üéâ"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
