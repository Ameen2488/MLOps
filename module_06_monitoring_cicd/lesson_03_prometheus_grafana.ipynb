{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 3: Prometheus & Grafana Basics\n",
                "\n",
                "**Module 6: Monitoring & CI/CD**  \n",
                "**Estimated Time**: 60 mins  \n",
                "**Difficulty**: Advanced\n",
                "\n",
                "---\n",
                "\n",
                "## üéØ Learning Objectives\n",
                "\n",
                "By the end of this lesson, you will:\n",
                "\n",
                "‚úÖ Understand **System Monitoring** (Latency, Throughput, Errors).  \n",
                "‚úÖ Use the `prometheus_client` library to expose metrics from Python.  \n",
                "‚úÖ Learn the architecture of **Prometheus** (Scraping) and **Grafana** (Visualizing).  \n",
                "‚úÖ Simulate a metrics endpoint.\n",
                "\n",
                "---\n",
                "\n",
                "## üìö Table of Contents\n",
                "\n",
                "1. [Functional vs Operational Monitoring](#1-monitoring-types)\n",
                "2. [Prometheus Architecture](#2-prometheus)\n",
                "3. [Hands-On: Exposing Metrics from Python](#3-hands-on)\n",
                "4. [Interview Preparation](#4-interview)\n",
                "\n",
                "---\n",
                "\n",
                "### üõ†Ô∏è Setup\n",
                "We need `prometheus_client`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pip install prometheus_client -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Functional vs Operational Monitoring\n",
                "\n",
                "| Support Type | Questions Answered | Tools |\n",
                "|---|---|---|\n",
                "| **Operational** | Is the server up? Is it slow? Is it running out of RAM? | Prometheus, Grafana, Datadog |\n",
                "| **Functional** | Is the model predicting garbage? Is the data drifting? | Evidently AI, Arize, Fiddler |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prometheus Architecture\n",
                "\n",
                "Prometheus is a **Time-Series Database (TSDB)**.\n",
                "\n",
                "### How it works (Pull Model):\n",
                "1. **You** add an endpoint `/metrics` to your FastAPI app.\n",
                "2. **Prometheus Server** visits `/metrics` every 15 seconds (scrapes).\n",
                "3. **Grafana** queries Prometheus to draw charts."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hands-On: Exposing Metrics from Python\n",
                "\n",
                "We will simulate a web server and expose:\n",
                "1. **Counter**: Total Requests (Only goes up).\n",
                "2. **Gauge**: Current Memory Usage (Goes up and down).\n",
                "3. **Histogram**: Latency (Buckets)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prometheus_client import start_http_server, Counter, Gauge, Histogram\n",
                "import time\n",
                "import random\n",
                "\n",
                "# 1. Define Metrics\n",
                "REQUEST_COUNT = Counter('app_requests_total', 'Total number of requests')\n",
                "MEMORY_USAGE = Gauge('app_memory_usage_bytes', 'Current memory usage')\n",
                "LATENCY = Histogram('app_request_latency_seconds', 'Request latency')\n",
                "\n",
                "# 2. Start Metrics Server\n",
                "# In a real app, this runs alongside FastAPI. Here we run it on port 8000.\n",
                "# start_http_server(8000)\n",
                "\n",
                "# 3. Simulate Traffic\n",
                "print(\"Simulating traffic... (Press Stop to end)\")\n",
                "\n",
                "for i in range(5):\n",
                "    # Increment Counter\n",
                "    REQUEST_COUNT.inc()\n",
                "    \n",
                "    # Set Gauge\n",
                "    mem = random.randint(200, 500) * 1024 * 1024 # 200-500 MB\n",
                "    MEMORY_USAGE.set(mem)\n",
                "    \n",
                "    # Observe Histogram\n",
                "    latency = random.random() * 0.5 # 0.0 - 0.5 seconds\n",
                "    LATENCY.observe(latency)\n",
                "    \n",
                "    print(f\"Request {i+1}: Latency={latency:.2f}s, Mem={mem/1024/1024:.0f}MB\")\n",
                "    time.sleep(0.5)\n",
                "\n",
                "print(\"Done. If you ran start_http_server, you could see this at localhost:8000/metrics\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Interview Preparation\n",
                "\n",
                "**Q1: Why use Prometheus (Pull) vs pushing metrics?**  \n",
                "*A1: Pulling prevents the server from being overwhelmed by a flood of apps trying to push data. It also makes it easier to tell if an app is DOWN (it stops responding to scrapes).*\n",
                "\n",
                "**Q2: What is the difference between a Counter and a Gauge?**  \n",
                "*A2: A Counter strictly increases (e.g., Total Errors). A Gauge can go up and down (e.g., CPU Temperature, Memory Usage).*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}