{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Project Step 2: Training & Tracking (Hydra + W&B)\n",
                "\n",
                "**Objective**: Train a YOLOv8 model while managing configs with **Hydra** and tracking results with **Weights & Biases**.\n",
                "\n",
                "**Why?**\n",
                "- **Hydra**: Avoids hardcoding parameters (`epochs=50`). Allows easy overrides.\n",
                "- **W&B**: Visualizes loss curves and validates if the model is learning.\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š Steps\n",
                "1. **Setup Config**: Create `conf/train.yaml`.\n",
                "2. **Load Config**: Use Hydra's Compose API.\n",
                "3. **Train Model**: Run YOLOv8 training.\n",
                "4. **Analyze Results**: View metrics in W&B."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Config (Hydra)\n",
                "\n",
                "We will programmatically create a YAML config file in `../conf/train.yaml`.\n",
                "In a real project, you would edit this file manually."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import yaml\n",
                "from hydra import compose, initialize\n",
                "from omegaconf import OmegaConf\n",
                "\n",
                "CONF_DIR = \"../conf\"\n",
                "os.makedirs(CONF_DIR, exist_ok=True)\n",
                "\n",
                "# Define the config structure\n",
                "config_data = \"\"\"\n",
                "defaults:\n",
                "  - _self_\n",
                "\n",
                "experiment:\n",
                "  name: \"yolo_baseline\"\n",
                "  project: \"cv_mlops_project\"\n",
                "\n",
                "model:\n",
                "  name: \"yolov8n.pt\"  # Nano model (fastest)\n",
                "\n",
                "training:\n",
                "  epochs: 5\n",
                "  batch_size: 16\n",
                "  img_size: 640\n",
                "  device: \"cpu\" # or 0 for GPU\n",
                "  workers: 2\n",
                "\"\"\"\n",
                "\n",
                "with open(os.path.join(CONF_DIR, \"train.yaml\"), \"w\") as f:\n",
                "    f.write(config_data)\n",
                "\n",
                "print(\"âœ… Config created at ../conf/train.yaml\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Config\n",
                "\n",
                "We simulate running `python train.py` by using Hydra's `initialize` and `compose`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Hydra (context manager needed for Jupyter)\n",
                "with initialize(version_base=None, config_path=\"../conf\"):\n",
                "    cfg = compose(config_name=\"train\")\n",
                "    \n",
                "print(\"--- Loaded Config ---\")\n",
                "print(OmegaConf.to_yaml(cfg))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train Model (YOLOv8)\n",
                "\n",
                "We use the `ultralytics` library. It has built-in support for W&B.\n",
                "Just calling `model.train()` with `project=` argument might trigger it, but let's be explicit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "import wandb\n",
                "\n",
                "# 1. Initialize W&B (Optional: Ultralytics does this automatically if installed, \n",
                "# but manual init ensures we control the project name)\n",
                "wandb.init(\n",
                "    project=cfg.experiment.project,\n",
                "    name=cfg.experiment.name,\n",
                "    config=OmegaConf.to_container(cfg)\n",
                ")\n",
                "\n",
                "# 2. Load Model\n",
                "model = YOLO(cfg.model.name)\n",
                "\n",
                "# 3. Train\n",
                "# Note: coco128.yaml is built-in to Ultralytics. \n",
                "# If using custom data, point to absolute path of data.yaml.\n",
                "print(f\"Starting training for {cfg.training.epochs} epochs...\")\n",
                "\n",
                "results = model.train(\n",
                "    data=\"coco128.yaml\",\n",
                "    epochs=cfg.training.epochs,\n",
                "    batch=cfg.training.batch_size,\n",
                "    imgsz=cfg.training.img_size,\n",
                "    device=cfg.training.device,\n",
                "    workers=cfg.training.workers,\n",
                "    project=\"../models\",\n",
                "    name=cfg.experiment.name,\n",
                "    exist_ok=True # Overwrite existing exp folder\n",
                ")\n",
                "\n",
                "wandb.finish()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analyze Results\n",
                "\n",
                "The training artifacts are saved in `../models/yolo_baseline`.\n",
                "We can inspect the validation metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Ultralytics saves a results.csv\n",
                "results_path = f\"../models/{cfg.experiment.name}/results.csv\"\n",
                "\n",
                "if os.path.exists(results_path):\n",
                "    df = pd.read_csv(results_path)\n",
                "    # Clean column names (strip whitespace)\n",
                "    df.columns = df.columns.str.strip()\n",
                "    \n",
                "    # Plot mAP50-95\n",
                "    print(\"--- Training Metrics (Last 5 Epochs) ---\")\n",
                "    print(df[['epoch', 'train/box_loss', 'metrics/mAP50-95(B)']].tail())\n",
                "    \n",
                "    # Simple Plot\n",
                "    df.plot(x='epoch', y='metrics/mAP50-95(B)', title=\"mAP over Epochs\")\n",
                "else:\n",
                "    print(\"Training failed or results file not found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Step\n",
                "\n",
                "You have a trained model! But it's in PyTorch (`.pt`) format. For production, we need something faster.\n",
                "\n",
                "Proceed to `03_optimization_onnx.ipynb`."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}