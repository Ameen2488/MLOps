{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 3: MLflow Basics\n",
                "\n",
                "**Module 2: Reproducibility & Versioning**  \n",
                "**Estimated Time**: 2-3 hours  \n",
                "**Difficulty**: Beginner-Intermediate\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸŽ¯ Learning Objectives\n",
                "\n",
                "By the end of this lesson, you will:\n",
                "\n",
                "âœ… Understand the 4 components of MLflow  \n",
                "âœ… Implement MLflow Tracking in Python scripts  \n",
                "âœ… Log parameters, metrics, and artifacts  \n",
                "âœ… Use the MLflow UI to compare experiments  \n",
                "âœ… Answer interview questions on experiment tracking  \n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š Table of Contents\n",
                "\n",
                "1. [What is MLflow?](#1-what-is-mlflow)\n",
                "2. [The MLflow Tracking Component](#2-tracking)\n",
                "3. [Hands-On: First MLflow Experiment](#3-hands-on)\n",
                "4. [Comparing Runs in UI](#4-comparing-runs)\n",
                "5. [Interview Preparation](#5-interview-questions)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. What is MLflow?\n",
                "\n",
                "MLflow is an open-source platform for the machine learning lifecycle. It has four main components:\n",
                "\n",
                "1. **MLflow Tracking**: Record and query experiments (code, data, config, results).\n",
                "2. **MLflow Projects**: Package data science code in a reproducible format.\n",
                "3. **MLflow Models**: Deploy machine learning models in diverse serving environments.\n",
                "4. **MLflow Registry**: Store, annotate, discover, and manage models.\n",
                "\n",
                "In this lesson, we focus on **Tracking**."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The MLflow Tracking Component\n",
                "\n",
                "### Why do we need it?\n",
                "\n",
                "Without tracking:\n",
                "- \"Which hyperparameters gave that 98% accuracy?\"\n",
                "- \"Where is the model file for the experiment I ran last Tuesday?\"\n",
                "- \"Did the new dataset update improve performance?\"\n",
                "\n",
                "MLflow solves this by logging:\n",
                "- **Parameters**: Key-value inputs (n_estimators=100, learning_rate=0.01)\n",
                "- **Metrics**: Numeric values that update (accuracy, loss)\n",
                "- **Artifacts**: Files (plots, models, data samples)\n",
                "- **Tags**: Metadata (user, git_commit_hash)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hands-On: First MLflow Experiment\n",
                "\n",
                "You need to have specific libraries installed (mlflow, sklearn, pandas).\n",
                "If not installed: `!pip install mlflow`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mlflow\n",
                "import mlflow.sklearn\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.datasets import load_diabetes\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# 1. Prepare Data\n",
                "db = load_diabetes()\n",
                "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
                "\n",
                "# 2. Define Training Function\n",
                "def train(n_estimators, max_depth):\n",
                "    # Start MLflow run\n",
                "    with mlflow.start_run():\n",
                "        # Log Parameters\n",
                "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
                "        mlflow.log_param(\"max_depth\", max_depth)\n",
                "        mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
                "        \n",
                "        # Create and Train Model\n",
                "        rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
                "        rf.fit(X_train, y_train)\n",
                "        \n",
                "        # Evaluate\n",
                "        predictions = rf.predict(X_test)\n",
                "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
                "        \n",
                "        # Log Metrics\n",
                "        mlflow.log_metric(\"rmse\", rmse)\n",
                "        \n",
                "        # Log Model (Artifact)\n",
                "        mlflow.sklearn.log_model(rf, \"model\")\n",
                "        \n",
                "        print(f\"Run Complete: n_est={n_estimators}, depth={max_depth}, RMSE={rmse:.4f}\")\n",
                "\n",
                "# 3. Run Experiments\n",
                "print(\"Starting Experiments...\")\n",
                "train(50, 5)\n",
                "train(100, 10)\n",
                "train(200, 15)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Comparing Runs in UI\n",
                "\n",
                "To see the results, you would typically run:\n",
                "```bash\n",
                "mlflow ui\n",
                "```\n",
                "And navigate to `http://localhost:5000`.\n",
                "\n",
                "### What to Look For:\n",
                "1. **Experiment List**: Usually 'Default' or named experiments.\n",
                "2. **Table View**: Compare RMSE across different runs.\n",
                "3. **Details Page**: Click a run to see execution time, parameters, and download the model artifact."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Interview Preparation\n",
                "\n",
                "### Common Questions\n",
                "\n",
                "#### Q1: \"What is the difference between logging a parameter and a metric?\"\n",
                "**Answer**: Parameters are inputs (config, hyperparameters) and are typically constant for a run. Metrics are outputs (accuracy, loss) and can change over time (e.g., loss per epoch).\n",
                "\n",
                "#### Q2: \"How would you track models across a team?\"\n",
                "**Answer**: Use a **remote tracking server** (e.g., on AWS EC2 or Managed MLflow on Databricks/Azure). Everyone points their `mlflow.set_tracking_uri()` to the shared server. This creates a central repository of all experiments for the team.\n",
                "\n",
                "#### Q3: \"What are MLflow Artifacts?\"\n",
                "**Answer**: Artifacts are output files generated by the run. Common examples: serialized model files (.pkl), plots (confusion matrix images), and data samples (CSV, Parquet). They are stored in an artifact store (S3, Azure Blob) while metadata is stored in a database (SQL)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}