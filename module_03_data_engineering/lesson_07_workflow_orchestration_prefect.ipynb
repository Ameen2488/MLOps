{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 7: Workflow Orchestration (Prefect)\n",
                "\n",
                "**Module 3: Data & Pipeline Engineering**  \n",
                "**Estimated Time**: 1-2 hours  \n",
                "**Difficulty**: Beginner-Intermediate\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸŽ¯ Learning Objectives\n",
                "\n",
                "By the end of this lesson, you will:\n",
                "\n",
                "âœ… Understand Python-native orchestration (Prefect vs Airflow)  \n",
                "âœ… Define **Flows** and **Tasks** using decorators  \n",
                "âœ… Implement automatic **Retries** and **Caching**  \n",
                "âœ… Answer interview questions on Pipeline Orchestration  \n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š Table of Contents\n",
                "\n",
                "1. [The \"Cron Job\" Problem](#1-cron-problem)\n",
                "2. [Introduction to Prefect](#2-intro-prefect)\n",
                "3. [Hands-On: First Prefect Flow](#3-hands-on)\n",
                "4. [Scheduling & UI](#4-scheduling)\n",
                "5. [Interview Preparation](#5-interview-questions)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. The \"Cron Job\" Problem\n",
                "\n",
                "You have a script `train_model.py`. You schedule it with Linux `cron` to run daily.\n",
                "\n",
                "**Issues**:\n",
                "1. **Failures**: If it fails, who knows? (You need to check logs).\n",
                "2. **Retries**: It doesn't retry automatically.\n",
                "3. **Dependencies**: Hard to say \"Run B only if A succeeds\".\n",
                "4. **History**: No dashboard of past runs.\n",
                "\n",
                "**Solution**: Use an Orchestrator (Airflow, Prefect, Dagster)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Introduction to Prefect\n",
                "\n",
                "Prefect is \"Modern Airflow\".\n",
                "- **Native Python**: No complex DSL concepts.\n",
                "- **Decorators**: Just add `@task` and `@flow` to your functions.\n",
                "- **Dynamic DAGs**: Logic is built at runtime."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hands-On: First Prefect Flow\n",
                "\n",
                "Note: Requires `pip install prefect`. We simulate the output structure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pseudo-code for Prefect 2.0 Syntax\n",
                "\n",
                "print(\"Concept Code - Prefect 2.0 flow definition\\n\")\n",
                "\n",
                "code = \"\"\"\n",
                "from prefect import task, flow\n",
                "import time\n",
                "\n",
                "# 1. Define Tasks\n",
                "@task(retries=3, retry_delay_seconds=10)\n",
                "def extract_data(url: str):\n",
                "    print(f\"Fetching {url}...\")\n",
                "    # return pd.read_csv(...)\n",
                "    return [1, 2, 3]\n",
                "\n",
                "@task\n",
                "def transform_data(data: list):\n",
                "    print(\"Cleaning data...\")\n",
                "    return [x * 10 for x in data]\n",
                "\n",
                "@task\n",
                "def load_data(data: list):\n",
                "    print(\"Saving to Database...\")\n",
                "    print(f\"Loaded: {data}\")\n",
                "\n",
                "# 2. Define Flow (The DAG)\n",
                "@flow(name=\"etl-pipeline-daily\")\n",
                "def main_flow():\n",
                "    raw = extract_data(\"s3://bucket/data.csv\")\n",
                "    clean = transform_data(raw)\n",
                "    load_data(clean)\n",
                "\n",
                "# 3. Run it\n",
                "if __name__ == '__main__':\n",
                "    main_flow()\n",
                "\"\"\"\n",
                "\n",
                "print(code)\n",
                "print(\"\\n--- OUTPUT SIMULATION ---\")\n",
                "print(\"15:00:00.000 | INFO | Created task run 'extract_data'\")\n",
                "print(\"15:00:00.500 | INFO | Fetching s3://bucket/data.csv...\")\n",
                "print(\"15:00:01.000 | INFO | Task run 'extract_data' completed\")\n",
                "print(\"15:00:01.100 | INFO | Created task run 'transform_data'\")\n",
                "print(\"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Scheduling & UI\n",
                "\n",
                "To schedule:\n",
                "```bash\n",
                "prefect deployment build my_flow.py:main_flow -n daily-etl -q test_queue --cron \"0 0 * * *\"\n",
                "prefect deployment apply main_flow-deployment.yaml\n",
                "```\n",
                "\n",
                "This creates a deployment that runs every day at midnight."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Interview Preparation\n",
                "\n",
                "### Common Questions\n",
                "\n",
                "#### Q1: \"Prefect vs Airflow?\"\n",
                "**Answer**: \"Airflow is the industry standard (maturity, ecosystem). Prefect is more modern and 'Pythonic'. Prefect handles dynamic workflows (loops, dynamic mapping) much better than Airflow's static DAG structure.\"\n",
                "\n",
                "#### Q2: \"How to handle Backfilling?\"\n",
                "**Answer**: \"If I fix a bug in the code today, I might need to re-process data from the last 30 days. Orchestrators allow you to trigger past runs (Backfill) easily, ensuring historical data consistency.\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}