{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 9: Load Testing (Locust)\n",
                "\n",
                "**Module 5: Model Deployment**  \n",
                "**Estimated Time**: 1 hour  \n",
                "**Difficulty**: Intermediate\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸŽ¯ Learning Objectives\n",
                "\n",
                "By the end of this lesson, you will:\n",
                "\n",
                "âœ… Understand **RPS** (Requests Per Second) and **P99 Latency**  \n",
                "âœ… Write a **Locust** script to stress test your API  \n",
                "âœ… Identify performance bottlenecks (CPU vs I/O)  \n",
                "âœ… Answer interview questions on scalability  \n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š Table of Contents\n",
                "\n",
                "1. [Why Load Test?](#1-why)\n",
                "2. [The Tool: Locust](#2-locust)\n",
                "3. [Hands-On: Stress Testing an API](#3-hands-on)\n",
                "4. [Interview Preparation](#4-interview-questions)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Why Load Test?\n",
                "\n",
                "It works on your machine. But what happens when 1,000 users hit it at once?\n",
                "- **Latency**: Does it slow down to 10 seconds?\n",
                "- **Errors**: Does it crash with 500 OOM (Out of Memory)?\n",
                "\n",
                "You must know your **Breaking Point** before Production."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The Tool: Locust\n",
                "\n",
                "Locust is a Python-based load testing tool.\n",
                "- You write \"User Behaviors\" in Python.\n",
                "- It spawns thousands of users to swarm your system.\n",
                "- It provides a Web UI with graphs."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hands-On: Stress Testing an API\n",
                "\n",
                "We write a `locustfile.py`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "locust_code = \"\"\"\n",
                "from locust import HttpUser, task, between\n",
                "import random\n",
                "\n",
                "class MLUser(HttpUser):\n",
                "    wait_time = between(1, 2)  # Wait 1-2s between tasks\n",
                "\n",
                "    @task\n",
                "    def predict_home(self):\n",
                "        # Send random data\n",
                "        payload = {\n",
                "            \"sqft\": random.randint(500, 3000),\n",
                "            \"bedrooms\": random.randint(1, 5),\n",
                "            \"location\": \"NY\"\n",
                "        }\n",
                "        self.client.post(\"/predict\", json=payload)\n",
                "\"\"\"\n",
                "\n",
                "print(locust_code)\n",
                "\n",
                "print(\"\\n--- Running Locust ---\")\n",
                "print(\"$ locust -f locustfile.py\")\n",
                "print(\"Then open http://localhost:8089\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Interview Preparation\n",
                "\n",
                "### Common Questions\n",
                "\n",
                "#### Q1: \"Your API has high latency. How do you debug?\"\n",
                "**Answer**: \"1. Check **CPU/Memory** usage (is it saturated?). 2. Check **I/O** (is it waiting for DB/S3?). 3. Profile the code (flame graph). If CPU is high, I need more replicas/Optimize model (ONNX). If I/O is high, I need async/caching.\"\n",
                "\n",
                "#### Q2: \"What is P99?\"\n",
                "**Answer**: \"The 99th Percentile Latency. Being 'fast on average' isn't enough. If P99 is 2s, it means 1 in 100 requests takes 2s. For a site with 1M users, that's 10,000 angry users per day. We optimize for P99/P99.9, not Average.\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}