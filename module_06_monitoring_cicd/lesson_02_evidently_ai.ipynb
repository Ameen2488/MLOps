{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 2: Drift Detection using Evidently AI\n",
                "\n",
                "**Module 6: Monitoring & CI/CD**  \n",
                "**Estimated Time**: 45 mins  \n",
                "**Difficulty**: Intermediate\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸŽ¯ Learning Objectives\n",
                "\n",
                "By the end of this lesson, you will:\n",
                "\n",
                "âœ… Install and use **Evidently AI**, the industry-standard open-source tool for ML monitoring.  \n",
                "âœ… Generate a **Data Drift Report** comparing Training vs Production data.  \n",
                "âœ… Interpret the visualized report (HTML/Dashboard).  \n",
                "âœ… Understand how to integrate this into a pipeline.\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š Table of Contents\n",
                "\n",
                "1. [Why not just manual scripts?](#1-why)\n",
                "2. [Deep Dive: Evidently AI](#2-evidently)\n",
                "3. [Hands-On: Generating a Drift Report](#3-hands-on)\n",
                "4. [Integration with Pipelines](#4-integration)\n",
                "5. [Interview Preparation](#5-interview)\n",
                "\n",
                "---\n",
                "\n",
                "### ðŸ› ï¸ Setup\n",
                "We need `evidently` and `sklearn` for sample data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pip install evidently scikit-learn pandas -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Why not just manual scripts?\n",
                "\n",
                "In Lesson 1, we wrote 20 lines of code to check for drift in *one* feature.\n",
                "In production, you have models with **50+ features**. Writing KS-tests for all of them, handling categorical variables, and creating plots is tedious.\n",
                "\n",
                "**Tools like Evidently AI** automate this:\n",
                "- Auto-detect categorical vs numerical.\n",
                "- Select appropriate statistical tests.\n",
                "- Generate beautiful HTML reports."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Deep Dive: Evidently AI\n",
                "\n",
                "Evidently works on the concept of **Reference** vs **Current** datasets.\n",
                "- **Reference**: The data you trained on (assumed to be \"Good\").\n",
                "- **Current**: The new batch of data from production.\n",
                "\n",
                "It produces **Reports** (Metric visualizations) and **Test Suites** (Pass/Fail checks)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hands-On: Generating a Drift Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from sklearn.datasets import load_iris\n",
                "\n",
                "from evidently.report import Report\n",
                "from evidently.metric_preset import DataDriftPreset\n",
                "\n",
                "# 1. Load Data\n",
                "iris = load_iris(as_frame=True)\n",
                "df = iris.frame\n",
                "\n",
                "# 2. Simulate Drift\n",
                "# Reference: First 75 rows\n",
                "ref_data = df.iloc[:75]\n",
                "# Current: Last 75 rows (Iris Virginica is different from Setosa!)\n",
                "curr_data = df.iloc[75:]\n",
                "\n",
                "# 3. Create Report\n",
                "report = Report(metrics=[\n",
                "    DataDriftPreset(), \n",
                "])\n",
                "\n",
                "report.run(reference_data=ref_data, current_data=curr_data)\n",
                "print(\"Report Generated!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. View Report\n",
                "# In Jupyter, this renders an interactive dashboard.\n",
                "report.show_html()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Export for Automation (CI/CD)\n",
                "# We can save it as JSON to parse programmatically\n",
                "report.save_json(\"drift_report.json\")\n",
                "\n",
                "import json\n",
                "with open(\"drift_report.json\") as f:\n",
                "    result = json.load(f)\n",
                "\n",
                "# Check if drift detected (True/False)\n",
                "drift_detected = result['metrics'][0]['result']['dataset_drift']\n",
                "print(f\"Is Dataset Drifted? {drift_detected}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Integration with Pipelines\n",
                "\n",
                "In a real MLOps pipeline (e.g., Airflow or GitHub Actions):\n",
                "\n",
                "1. **Extract** `current_batch.csv`.\n",
                "2. **Load** `reference.csv`.\n",
                "3. **Run** Evidently script.\n",
                "4. **If Drift Detected** -> Trigger Retraining or Send Slack Alert.\n",
                "5. **Save** HTML report to S3 for data scientists to debug."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Interview Preparation\n",
                "\n",
                "**Q1: How would you automate drift detection?**  \n",
                "*A1: I would run a daily job (Airflow) that uses a tool like Evidently AI to compare yesterday's inference data against the training set. If the drift score exceeds a threshold (e.g., 0.5), I'd trigger an alert.*\n",
                "\n",
                "**Q2: Does drift always mean we need to retrain?**  \n",
                "*A2: No. Sometimes drift is temporary (e.g., Black Friday traffic). Also, if the model performance (accuracy) hasn't dropped, the drift might be on unimportant features.*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}