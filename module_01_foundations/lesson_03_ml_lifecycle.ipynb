{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lesson 3: The ML System Lifecycle\n",
                "\n",
                "**Module 1: Foundations & Background**  \n",
                "**Estimated Time**: 3-4 hours  \n",
                "**Difficulty**: Intermediate\n",
                "\n",
                "---\n",
                "\n",
                "## üéØ Learning Objectives\n",
                "\n",
                "By the end of this lesson, you will:\n",
                "\n",
                "‚úÖ Understand the complete ML system lifecycle  \n",
                "‚úÖ Know each stage: Data ‚Üí Train ‚Üí Deploy ‚Üí Monitor  \n",
                "‚úÖ Identify challenges at each stage  \n",
                "‚úÖ Build a simple end-to-end ML pipeline  \n",
                "‚úÖ Answer lifecycle questions in interviews  \n",
                "\n",
                "---\n",
                "\n",
                "## üìö What You'll Learn\n",
                "\n",
                "1. [The Complete ML Lifecycle](#1-complete-lifecycle)\n",
                "2. [Stage 1: Data Collection & Processing](#2-data-stage)\n",
                "3. [Stage 2: Model Training](#3-training-stage)\n",
                "4. [Stage 3: Model Deployment](#4-deployment-stage)\n",
                "5. [Stage 4: Monitoring & Maintenance](#5-monitoring-stage)\n",
                "6. [Hands-On: End-to-End Pipeline](#6-hands-on)\n",
                "7. [Interview Preparation](#7-interview-prep)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. The Complete ML Lifecycle\n",
                "\n",
                "### Overview\n",
                "\n",
                "The ML system lifecycle extends far beyond just training a model. It encompasses the entire journey from raw data to a production system that delivers value.\n",
                "\n",
                "### The Four Main Stages\n",
                "\n",
                "```\n",
                "DATA ‚Üí TRAIN ‚Üí DEPLOY ‚Üí MONITOR\n",
                " ‚Üë                         ‚Üì\n",
                " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Feedback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```\n",
                "\n",
                "1. **Data**: Collection, validation, cleaning, feature engineering.\n",
                "2. **Train**: Model selection, training, hyperparameter tuning, evaluation.\n",
                "3. **Deploy**: Packaging, testing, serving infrastructure, rollout.\n",
                "4. **Monitor**: Tracking performance, drift detection, retraining.\n",
                "\n",
                "### Time Distribution\n",
                "\n",
                "In production, you will spend most of your time on **Data** and **Monitoring/Infrastructure**, rather than just training."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Stage 1: Data Collection & Processing\n",
                "\n",
                "**\"Garbage in, garbage out.\"**\n",
                "\n",
                "### Key Activities\n",
                "- **Collection**: APIs, databases, logs, scraping.\n",
                "- **Validation**: Checking schema, types, ranges, missing values.\n",
                "- **Cleaning**: Handling nulls, outliers, duplicates.\n",
                "- **Feature Engineering**: Creating predictive features.\n",
                "- **Versioning**: Using DVC to track dataset versions.\n",
                "\n",
                "### Common Challenges\n",
                "- **Data Leakage**: Using future information in training.\n",
                "- **Training-Serving Skew**: Differences between offline training data and live production data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Stage 2: Model Training\n",
                "\n",
                "### Key Activities\n",
                "- **Baseline**: Start with a simple model (dummy, logistic regression).\n",
                "- **Experimentation**: Try different algorithms (Trees, NNs).\n",
                "- **Hyperparameter Tuning**: Grid search, random search, Bayesian opt.\n",
                "- **Evaluation**: Accuracy, Precision, Recall, F1, ROC-AUC.\n",
                "- **Tracking**: Use MLflow or Weights & Biases to log experiments.\n",
                "\n",
                "### Validation Strategy\n",
                "Always use a **Holdout Set** or **Cross-Validation** to estimate generalization performance."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Stage 3: Model Deployment\n",
                "\n",
                "### Key Activities\n",
                "- **Packaging**: Serialize model (pickle, ONNX) and dependencies (Docker).\n",
                "- **Serving**: Expose as API (FastAPI) or Batch Job.\n",
                "- **Infrastructure**: Kubernetes, AWS SageMaker, etc.\n",
                "- **Rollout**: Canary deployment (gradual), Blue-Green deployment.\n",
                "\n",
                "### Challenges\n",
                "- **Latency**: Serving predictions in milliseconds.\n",
                "- **Throughput**: Handling thousands of requests per second."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Stage 4: Monitoring & Maintenance\n",
                "\n",
                "### Key Activities\n",
                "- **System Monitoring**: CPU, memory, latency, errors.\n",
                "- **Model Monitoring**: Prediction distribution, null outputs.\n",
                "- **Drift Detection**: Checking if input data statistics have changed.\n",
                "- **Retraining**: Automating updates when performance drops.\n",
                "\n",
                "### Feedback Loop\n",
                "Use production data to label new examples and retrain the model, creating a virtuous cycle."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Hands-On: End-to-End Pipeline\n",
                "\n",
                "Let's implement a simplified version of this lifecycle in Python."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìä STAGE 1: DATA COLLECTION & PREP\n",
                        "   Data shape: (2000, 21)\n",
                        "   Target distribution:\n",
                        "target\n",
                        "0    1002\n",
                        "1     998\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "ü§ñ STAGE 2: MODEL TRAINING\n",
                        "   Model Accuracy: 0.9350\n",
                        "   Classification Report:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.94      0.93      0.94       204\n",
                        "           1       0.93      0.94      0.93       196\n",
                        "\n",
                        "    accuracy                           0.94       400\n",
                        "   macro avg       0.93      0.94      0.93       400\n",
                        "weighted avg       0.94      0.94      0.94       400\n",
                        "\n",
                        "\n",
                        "üöÄ STAGE 3: DEPLOYMENT\n",
                        "   Model saved to models/rf_model_v1.pkl\n",
                        "   ModelService initialized and ready.\n",
                        "\n",
                        "üìà STAGE 4: MONITORING\n",
                        "   Incoming request: [-2.56758512 -0.26884104 -0.53058036  0.2715822   0.29151146]...\n",
                        "   Prediction: 1\n",
                        "   Training Mean: -0.004\n",
                        "   Production Mean: -0.002\n",
                        "   ‚úÖ Data statistics look stable.\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.datasets import make_classification\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "# ==========================================\n",
                "# 1. DATA STAGE\n",
                "# ==========================================\n",
                "print(\"üìä STAGE 1: DATA COLLECTION & PREP\")\n",
                "# Simulate collecting data\n",
                "X, y = make_classification(n_samples=2000, n_features=20, random_state=42)\n",
                "df = pd.DataFrame(X, columns=[f'feat_{i}' for i in range(20)])\n",
                "df['target'] = y\n",
                "\n",
                "# Data Validation (Simplified)\n",
                "assert df.isnull().sum().sum() == 0, \"Data contains nulls!\"\n",
                "print(f\"   Data shape: {df.shape}\")\n",
                "print(f\"   Target distribution:\\n{df['target'].value_counts()}\")\n",
                "\n",
                "# Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# ==========================================\n",
                "# 2. TRAINING STAGE\n",
                "# ==========================================\n",
                "print(\"\\nü§ñ STAGE 2: MODEL TRAINING\")\n",
                "# Experiment: Random Forest\n",
                "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Evaluation\n",
                "y_pred = model.predict(X_test)\n",
                "acc = accuracy_score(y_test, y_pred)\n",
                "print(f\"   Model Accuracy: {acc:.4f}\")\n",
                "print(\"   Classification Report:\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# ==========================================\n",
                "# 3. DEPLOYMENT STAGE (Simulation)\n",
                "# ==========================================\n",
                "print(\"\\nüöÄ STAGE 3: DEPLOYMENT\")\n",
                "# Serialize model\n",
                "os.makedirs('models', exist_ok=True)\n",
                "model_path = 'models/rf_model_v1.pkl'\n",
                "joblib.dump(model, model_path)\n",
                "print(f\"   Model saved to {model_path}\")\n",
                "\n",
                "# Simulate API\n",
                "class ModelService:\n",
                "    def __init__(self, path):\n",
                "        self.model = joblib.load(path)\n",
                "    \n",
                "    def predict(self, features):\n",
                "        # Expects features as list or array\n",
                "        return self.model.predict([features])[0]\n",
                "\n",
                "service = ModelService(model_path)\n",
                "print(\"   ModelService initialized and ready.\")\n",
                "\n",
                "# ==========================================\n",
                "# 4. MONITORING STAGE (Simulation)\n",
                "# ==========================================\n",
                "print(\"\\nüìà STAGE 4: MONITORING\")\n",
                "# Simulate incoming production traffic\n",
                "sample_request = X_test[0]\n",
                "prediction = service.predict(sample_request)\n",
                "print(f\"   Incoming request: {sample_request[:5]}...\")\n",
                "print(f\"   Prediction: {prediction}\")\n",
                "\n",
                "# Simple Drift Check (Simulation)\n",
                "prod_batch = X_test[:100]  # Simulate 100 requests\n",
                "train_mean = X_train.mean()\n",
                "prod_mean = prod_batch.mean()\n",
                "print(f\"   Training Mean: {train_mean:.3f}\")\n",
                "print(f\"   Production Mean: {prod_mean:.3f}\")\n",
                "if abs(train_mean - prod_mean) > 0.1:\n",
                "    print(\"   ‚ö†Ô∏è ALERT: Possible Data Drift Detected!\")\n",
                "else:\n",
                "    print(\"   ‚úÖ Data statistics look stable.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Interview Preparation\n",
                "\n",
                "### Top Questions\n",
                "\n",
                "#### 1. \"Walk me through the lifecycle of an ML system you built.\"\n",
                "**Answer Framework (STAR)**:\n",
                "- **Situation**: We needed to reduce fraud.\n",
                "- **Task**: Build a real-time detection system.\n",
                "- **Action**:\n",
                "  - Collected transaction logs (Data).\n",
                "  - Trained an XGBoost model, tuned hyperparameters (Train).\n",
                "  - Deployed as a FastAPI service on Kubernetes (Deploy).\n",
                "  - Set up Prometheus to track latency and drift (Monitor).\n",
                "- **Result**: Caught 20% more fraud, latency < 50ms.\n",
                "\n",
                "#### 2. \"What happens after you deploy a model?\"\n",
                "**Key Answer**: Monitoring and Feedback Loops.\n",
                "- Monitor technical metrics (latency, errors).\n",
                "- Monitor functional metrics (accuracy, drift).\n",
                "- Retrain strategies (scheduled vs triggered).\n",
                "\n",
                "#### 3. \"How do you know when to retrain?\"\n",
                "**Key Answer**: \n",
                "- **Performance Degradation**: Accuracy drops below threshold.\n",
                "- **Data Drift**: Input distribution changes significantly.\n",
                "- **New Data**: Significant volume of new labeled data available."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
